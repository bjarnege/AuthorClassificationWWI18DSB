{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/anaconda3/lib/python3.8/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# universally modules\n",
    "import re\n",
    "import sys\n",
    "import regex\n",
    "import nltk.data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "# preprocessing and transformation modules\n",
    "import fasttext\n",
    "import Preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# model algorithm\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "# evaluation modules\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to speed up the process choose a sample size to randomly draw a sample of the whole daataset\n",
    "sample_size = 100_000\n",
    "\n",
    "# remove all text that contain less than n chars\n",
    "min_chars_per_text = 50\n",
    "\n",
    "# which features will be used for the TF-IDF transformation\n",
    "text_features = \"text_preprocessed\"\n",
    "\n",
    "#### define the target variable and categorial variables used in later transformations ###\n",
    "#### Case 1: gender \n",
    "target_variable = \"gender\"\n",
    "categorial_variables =  [\"topic\", \"sign\"]\n",
    "\n",
    "# Case 2: topic\n",
    "#target_variable = \"topic\"\n",
    "#categorial_variables =  [\"gender\", \"sign\"]\n",
    "\n",
    "# Case 3: age\n",
    "#target_variable = \"age\"\n",
    "#categorial_variables =  [\"topic\", \"gender\", \"sign\"]\n",
    "\n",
    "# Case 4: sign\n",
    "#target_variable = \"sign\"\n",
    "#categorial_variables =  [\"gender\", \"topic\"]\n",
    "############################################################################################\n",
    "\n",
    "# use only words that occur at least sqrt_3(X) times \n",
    "min_df_exponent = (1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "df = pd.read_csv(\"../resource/data/blogtext.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493508</th>\n",
       "      <td>2114453</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>Law</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>22,April,2004</td>\n",
       "      <td>From the Sublime to the Ridiculous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364627</th>\n",
       "      <td>3509949</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>Education</td>\n",
       "      <td>Leo</td>\n",
       "      <td>07,July,2004</td>\n",
       "      <td>Imagine,if you will, 700 sleep-deprived...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312781</th>\n",
       "      <td>581839</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>02,August,2004</td>\n",
       "      <td>alrighty then... my sister has been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268110</th>\n",
       "      <td>1325355</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>28,June,2004</td>\n",
       "      <td>Diana, Happy belated birthday!  It soun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207575</th>\n",
       "      <td>1788812</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>08,August,2004</td>\n",
       "      <td>urlLink    It's me!&amp;nbsp; urlLink ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458296</th>\n",
       "      <td>518116</td>\n",
       "      <td>female</td>\n",
       "      <td>27</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>12,June,2002</td>\n",
       "      <td>ok...see 6/3/02...started to think I ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369006</th>\n",
       "      <td>1609589</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>27,May,2004</td>\n",
       "      <td>Dustin said I should update, so I am- I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68226</th>\n",
       "      <td>320176</td>\n",
       "      <td>male</td>\n",
       "      <td>45</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>16,May,2004</td>\n",
       "      <td>From the story it sounds like he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255722</th>\n",
       "      <td>106651</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>01,June,2004</td>\n",
       "      <td>The title of the page reads ' url...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631101</th>\n",
       "      <td>4059818</td>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>28,Juli,2004</td>\n",
       "      <td>我妹說可以幫我們做 banner, 可是她問我們要用什麼 顏色 做主色...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  gender  age       topic       sign            date  \\\n",
       "493508  2114453  female   24         Law     Cancer   22,April,2004   \n",
       "364627  3509949  female   23   Education        Leo    07,July,2004   \n",
       "312781   581839  female   16     Student     Taurus  02,August,2004   \n",
       "268110  1325355  female   26      indUnk     Cancer    28,June,2004   \n",
       "207575  1788812    male   25  Consulting     Taurus  08,August,2004   \n",
       "...         ...     ...  ...         ...        ...             ...   \n",
       "458296   518116  female   27      indUnk     Pisces    12,June,2002   \n",
       "369006  1609589    male   16     Student  Capricorn     27,May,2004   \n",
       "68226    320176    male   45  Publishing    Scorpio     16,May,2004   \n",
       "255722   106651    male   25      indUnk        Leo    01,June,2004   \n",
       "631101  4059818    male   27      indUnk    Scorpio    28,Juli,2004   \n",
       "\n",
       "                                                     text  \n",
       "493508              From the Sublime to the Ridiculous...  \n",
       "364627         Imagine,if you will, 700 sleep-deprived...  \n",
       "312781             alrighty then... my sister has been...  \n",
       "268110         Diana, Happy belated birthday!  It soun...  \n",
       "207575              urlLink    It's me!&nbsp; urlLink ...  \n",
       "...                                                   ...  \n",
       "458296         ok...see 6/3/02...started to think I ha...  \n",
       "369006         Dustin said I should update, so I am- I...  \n",
       "68226                From the story it sounds like he ...  \n",
       "255722               The title of the page reads ' url...  \n",
       "631101             我妹說可以幫我們做 banner, 可是她問我們要用什麼 顏色 做主色...  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw random sample for faster processing:\n",
    "df = df.sample(sample_size)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for a mininmal number of letters in a tweet:\n",
    "df = df[df[\"text\"].str.count(r\"[a-zA-Z]\") >= min_chars_per_text]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def findDates(text):\n",
    "#    try:\n",
    "#        return len([date for date in\\\n",
    "#                    datefinder.find_dates(text)])\n",
    "#    except:\n",
    "#        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildFeatures(text):\n",
    "    text_split = text.split()\n",
    "    len_text = len(text)\n",
    "    sentence_split = tokenizer.tokenize(text)\n",
    "    \n",
    "    # find the number of urls in the text\n",
    "    keywords = [\"urlLink\",\"http\",\"www\"]\n",
    "    nb_urls = sum((any(keyword in pattern for keyword in keywords))\\\n",
    "               for pattern in text.split())\n",
    "    # find the number of mails in the text\n",
    "    nb_mails = len(re.findall(r\"([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+|\\bmail\\b)\"\\\n",
    "                      ,text))\n",
    "    \n",
    "    # find the number of dates in the text\n",
    "#    nb_dates = findDates(text)\n",
    "     \n",
    "    # find characteristics about the usage of letters, numbers and symbols\n",
    "    uppercase_ratio = len(re.findall(r'[A-Z]', text))/len_text\n",
    "    lowercase_ratio = len(re.findall(r'[a-z]', text))/len_text\n",
    "    number_ratio = len(re.findall(r'[0-9]', text))/len_text\n",
    "    symbol_ratio = len(re.findall(r'[$-/:-?{-~!\"^_`\\[\\]]', text))/len_text\n",
    "\n",
    "    # find characteristics about the letters per word\n",
    "    sentence_len_word = [len(word) for word in text_split]\n",
    "    avg_letters_per_word = np.mean([len(word) for word in text_split])\n",
    "    var_letters_per_word = np.var([len(word) for word in text_split])\n",
    "    unique_words_ratio = len(set(text_split))/len(text_split)\n",
    "\n",
    "    # find characteristics about the letters per sentence\n",
    "    sentence_len_list = [len(sentence) for sentence in sentence_split]\n",
    "    avg_letters_per_sentence = np.mean(sentence_len_list)\n",
    "    var_letters_per_sentence = np.var(sentence_len_list)\n",
    "    \n",
    "    # find characteristics about the words per sentence\n",
    "    words_per_sentence_len_list = [len(sentence.split()) for sentence in sentence_split]\n",
    "    avg_words_per_sentence = np.mean(words_per_sentence_len_list)\n",
    "    var_words_per_sentence = np.var(words_per_sentence_len_list)\n",
    "    \n",
    "    # find the trumps\n",
    "    uppercase_per_sentence_ratio = [len(re.findall(r'[A-Z]', sentence))/len(sentence)\\\n",
    "                                    for sentence in sentence_split]\n",
    "    max_sentence_uppercase_ratio = max(uppercase_per_sentence_ratio)\n",
    "    max_sentence_uppercase_len = len(sentence_split[uppercase_per_sentence_ratio.index(max_sentence_uppercase_ratio)])\n",
    "    \n",
    "    return len_text, nb_urls, nb_mails,\\\n",
    "           uppercase_ratio, lowercase_ratio, number_ratio, symbol_ratio,\\\n",
    "           avg_letters_per_word, var_letters_per_word, unique_words_ratio,\\\n",
    "           avg_letters_per_sentence, var_letters_per_sentence,\\\n",
    "           avg_words_per_sentence, var_words_per_sentence,\\\n",
    "           max_sentence_uppercase_ratio, max_sentence_uppercase_len        \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:00<00:00, 702.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# append the data\n",
    "features = [buildFeatures(text) for text  in tqdm(df[\"text\"])]\n",
    "\n",
    "# append the data\n",
    "columns = [\"Text length\", \"Number URLs\", \"Number mails\",\\\n",
    "          \"Uppercase ratio\", \"Lowercase ratio\", \"Number ratio\", \"Symbol ratio\",\\\n",
    "          \"Average letters per word\", \"Variance of letters per word\", \"Unique words ratio\",\\\n",
    "          \"Average letters per sentence\", \"Variance of letters per sentence\",\\\n",
    "          \"Average words per sentence\", \"Variance of words per sentence\",\\\n",
    "          \"Maximal uppercase ratio per sentence\", \"Length of the maximal uppercase ratio sentence\"]\n",
    "\n",
    "# merge the features with the original dataset\n",
    "df_preprocessed = df.merge(pd.DataFrame(features, columns=columns), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:03<00:00, 26.32it/s]\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "100%|██████████| 88/88 [00:00<00:00, 4712.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# use the preprocessing  module\n",
    "preprocessor = Preprocessing.Preprocessing()\n",
    "df_preprocessed[\"text_preprocessed\"] = preprocessor.ProcessMany(df_preprocessed[\"text\"])\n",
    "\n",
    "# predict the main language\n",
    "model = fasttext.load_model('../src/data/lid.176.ftz')\n",
    "df_preprocessed[\"main_language\"] = [model.predict(text)[0][0].split(\"__\")[-1] for text in tqdm(df_preprocessed[\"text_preprocessed\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii_words(text):\n",
    "    return \"\".join([f\"{word} \" for word in text.split() if len(re.findall(r'[^\\x00-\\x7f]', word)) == 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecassary features\n",
    "df_filtered = df_preprocessed[(df_preprocessed[\"main_language\"] == \"en\")]\\\n",
    "                .drop([\"id\",\"text\",\"date\",\"main_language\"], axis= 1)\n",
    "\n",
    "# remove all words with non-ascii chars\n",
    "df_filtered[\"text_preprocessed\"] = df_filtered[\"text_preprocessed\"].apply(remove_non_ascii_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedTransformation:\n",
    "    \n",
    "    def  __init__(self, X=None, y=None, numerical_transformer=None, text_transformer=None, text_features=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.numerical_transformer = numerical_transformer\n",
    "        self.text_transformer = text_transformer\n",
    "        self.text_features = text_features\n",
    "        \n",
    "    def data_split(self, X, y, test_size= 0.2):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "        \n",
    "    def build_transformer(self, X=None, y=None,\\\n",
    "                          numerical_transformer=None, text_transformer=None, text_features=None):\n",
    "        # check if variables are present\n",
    "        if X == None:\n",
    "            X = self.X\n",
    "        if y == None:\n",
    "            y = self.y\n",
    "        if numerical_transformer == None:\n",
    "            numerical_transformer = self.numerical_transformer\n",
    "        if text_transformer == None:\n",
    "            text_transformer = self.text_transformer\n",
    "        if text_features == None:\n",
    "            text_features = self.text_features\n",
    "\n",
    "        # split the data\n",
    "        \n",
    "        self.data_split(X, y)\n",
    "        \n",
    "        # Create datasets for each classifier\n",
    "        self.X_train_text = self.X_train[text_features]\n",
    "        self.X_test_text =  self.X_test[text_features]\n",
    "        \n",
    "        self.X_train_numerical = self.X_train.drop(text_features, axis=1)\n",
    "        self.X_test_numerical = self.X_test.drop(text_features, axis=1)\n",
    "\n",
    "        # create transformers \n",
    "        self.numerical_transformer = numerical_transformer\n",
    "        self.text_transformer = text_transformer\n",
    "        \n",
    "        #create transformed training batches\n",
    "        self.X_train_numerical_transformed = self.numerical_transformer.fit_transform(self.X_train_numerical)\n",
    "        self.X_test_numerical_transformed = self.numerical_transformer.transform(self.X_test_numerical)\n",
    "\n",
    "        self.X_train_text_transformed = self.text_transformer.fit_transform(self.X_train_text)\n",
    "        self.X_test_text_transformed = self.text_transformer.transform(self.X_test_text)\n",
    "\n",
    "    def transform_one(self, text):\n",
    "        entry = pd.DataFrame(columns=text.keys())\n",
    "        entry = entry.append(text, ignore_index=True)\n",
    "        \n",
    "        # create datasets for each transformer\n",
    "        entry_text = entry[text_features]\n",
    "        entry_numerical = entry.drop(text_features, axis=1)\n",
    "        \n",
    "        entry_numerical_transformed = self.numerical_transformer.transform(entry_numerical)\n",
    "        entry_text_transformed = self.text_transformer.transform(entry_text)\n",
    "        \n",
    "        return {\"transformed_text\": entry_text_transformed,\\\n",
    "               \"transformed_numerical\": entry_numerical_transformed}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = df_filtered.drop(target_variable, axis=1),df_filtered[target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the  text transformer class to create two transformers for the textual and the numerical model\n",
    "text_transformer = TfidfVectorizer(ngram_range=(1,1), min_df=int(len(X)**(min_df_exponent)))\n",
    "numerical_transformer = make_column_transformer((OneHotEncoder(handle_unknown=\"ignore\"), categorial_variables)\\\n",
    "                                                       , remainder=StandardScaler())\n",
    "\n",
    "stacking = StackedTransformation(X, y, numerical_transformer, text_transformer, text_features)\n",
    "stacking.build_transformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11</th>\n",
       "      <th>15</th>\n",
       "      <th>200</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>add</th>\n",
       "      <th>age</th>\n",
       "      <th>ago</th>\n",
       "      <th>anymore</th>\n",
       "      <th>apparently</th>\n",
       "      <th>...</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>worry</th>\n",
       "      <th>write</th>\n",
       "      <th>wrong</th>\n",
       "      <th>ya</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.145061</td>\n",
       "      <td>0.166575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.13967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079115</td>\n",
       "      <td>0.103119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105466</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.102620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057546</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036435</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173318</td>\n",
       "      <td>0.225903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115523</td>\n",
       "      <td>0.182459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132550</td>\n",
       "      <td>0.253279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          11        15  200       act  action  add       age      ago  \\\n",
       "0   0.000000  0.000000  0.0  0.000000     0.0  0.0  0.000000  0.00000   \n",
       "1   0.000000  0.000000  0.0  0.000000     0.0  0.0  0.000000  0.00000   \n",
       "2   0.000000  0.000000  0.0  0.000000     0.0  0.0  0.000000  0.00000   \n",
       "3   0.000000  0.000000  0.0  0.167960     0.0  0.0  0.000000  0.00000   \n",
       "4   0.000000  0.000000  0.0  0.000000     0.0  0.0  0.000000  0.00000   \n",
       "..       ...       ...  ...       ...     ...  ...       ...      ...   \n",
       "64  0.145061  0.166575  0.0  0.000000     0.0  0.0  0.000000  0.13967   \n",
       "65  0.102620  0.000000  0.0  0.117839     0.0  0.0  0.000000  0.00000   \n",
       "66  0.000000  0.000000  0.0  0.115092     0.0  0.0  0.057546  0.00000   \n",
       "67  0.000000  0.000000  0.0  0.000000     0.0  0.0  0.000000  0.00000   \n",
       "68  0.000000  0.000000  0.0  0.000000     0.0  0.0  0.000000  0.00000   \n",
       "\n",
       "    anymore  apparently  ...      word      work     world  worry     write  \\\n",
       "0       0.0         0.0  ...  0.000000  0.000000  0.000000    0.0  0.000000   \n",
       "1       0.0         0.0  ...  0.000000  0.000000  0.000000    0.0  0.000000   \n",
       "2       0.0         0.0  ...  0.000000  0.000000  0.000000    0.0  0.000000   \n",
       "3       0.0         0.0  ...  0.000000  0.000000  0.000000    0.0  0.123859   \n",
       "4       0.0         0.0  ...  0.000000  0.000000  0.000000    0.0  0.000000   \n",
       "..      ...         ...  ...       ...       ...       ...    ...       ...   \n",
       "64      0.0         0.0  ...  0.079115  0.103119  0.000000    0.0  0.000000   \n",
       "65      0.0         0.0  ...  0.000000  0.000000  0.000000    0.0  0.000000   \n",
       "66      0.0         0.0  ...  0.054663  0.000000  0.052225    0.0  0.000000   \n",
       "67      0.0         0.0  ...  0.173318  0.225903  0.000000    0.0  0.000000   \n",
       "68      0.0         0.0  ...  0.000000  0.000000  0.000000    0.0  0.000000   \n",
       "\n",
       "       wrong        ya      yeah      year  yesterday  \n",
       "0   0.000000  0.000000  0.000000  0.000000   0.000000  \n",
       "1   0.000000  0.000000  0.000000  0.000000   0.000000  \n",
       "2   0.000000  0.000000  0.000000  0.000000   0.000000  \n",
       "3   0.000000  0.159545  0.000000  0.000000   0.000000  \n",
       "4   0.000000  0.000000  0.000000  0.000000   0.000000  \n",
       "..       ...       ...       ...       ...        ...  \n",
       "64  0.067423  0.000000  0.000000  0.105466   0.000000  \n",
       "65  0.190788  0.000000  0.000000  0.000000   0.000000  \n",
       "66  0.093170  0.000000  0.000000  0.036435   0.000000  \n",
       "67  0.000000  0.000000  0.000000  0.115523   0.182459  \n",
       "68  0.000000  0.132550  0.253279  0.000000   0.000000  \n",
       "\n",
       "[69 rows x 216 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features = stacking.text_transformer.get_feature_names()\n",
    "text_data = stacking.X_train_text_transformed.toarray()\n",
    "\n",
    "df_text_cluster = pd.DataFrame(text_data, columns=text_features)\n",
    "df_text_cluster\n",
    "\n",
    "# Die Features beschreiben die Worte im Text\n",
    "# Die Werte sind die TF*IDF-transformierten Textdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_Agriculture</th>\n",
       "      <th>x0_Architecture</th>\n",
       "      <th>x0_Arts</th>\n",
       "      <th>x0_Communications-Media</th>\n",
       "      <th>x0_Consulting</th>\n",
       "      <th>x0_Education</th>\n",
       "      <th>x0_Engineering</th>\n",
       "      <th>x0_HumanResources</th>\n",
       "      <th>x0_Internet</th>\n",
       "      <th>x0_Law</th>\n",
       "      <th>...</th>\n",
       "      <th>Symbol ratio</th>\n",
       "      <th>Average letters per word</th>\n",
       "      <th>Variance of letters per word</th>\n",
       "      <th>Unique words ratio</th>\n",
       "      <th>Average letters per sentence</th>\n",
       "      <th>Variance of letters per sentence</th>\n",
       "      <th>Average words per sentence</th>\n",
       "      <th>Variance of words per sentence</th>\n",
       "      <th>Maximal uppercase ratio per sentence</th>\n",
       "      <th>Length of the maximal uppercase ratio sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.188966</td>\n",
       "      <td>-0.211855</td>\n",
       "      <td>-0.141969</td>\n",
       "      <td>0.249935</td>\n",
       "      <td>-0.109786</td>\n",
       "      <td>-0.209599</td>\n",
       "      <td>-0.100388</td>\n",
       "      <td>-0.235177</td>\n",
       "      <td>-0.258180</td>\n",
       "      <td>0.348741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.760447</td>\n",
       "      <td>-0.032599</td>\n",
       "      <td>-0.199648</td>\n",
       "      <td>0.076483</td>\n",
       "      <td>-0.321340</td>\n",
       "      <td>-0.309126</td>\n",
       "      <td>-0.327829</td>\n",
       "      <td>-0.285257</td>\n",
       "      <td>-0.321831</td>\n",
       "      <td>-0.333540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.699487</td>\n",
       "      <td>-0.251692</td>\n",
       "      <td>-0.255734</td>\n",
       "      <td>1.601238</td>\n",
       "      <td>0.097803</td>\n",
       "      <td>-0.399956</td>\n",
       "      <td>0.048626</td>\n",
       "      <td>-0.353575</td>\n",
       "      <td>-0.788451</td>\n",
       "      <td>0.262183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733598</td>\n",
       "      <td>-0.806096</td>\n",
       "      <td>-0.252732</td>\n",
       "      <td>0.099943</td>\n",
       "      <td>-0.421116</td>\n",
       "      <td>-0.374826</td>\n",
       "      <td>-0.407464</td>\n",
       "      <td>-0.328854</td>\n",
       "      <td>-0.852262</td>\n",
       "      <td>-0.175699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.655676</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>-0.126142</td>\n",
       "      <td>1.362211</td>\n",
       "      <td>0.977000</td>\n",
       "      <td>-0.399956</td>\n",
       "      <td>0.958393</td>\n",
       "      <td>-0.353575</td>\n",
       "      <td>-0.694032</td>\n",
       "      <td>1.087031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536923</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>0.203957</td>\n",
       "      <td>-0.927789</td>\n",
       "      <td>1.000337</td>\n",
       "      <td>5.946264</td>\n",
       "      <td>0.917610</td>\n",
       "      <td>3.613456</td>\n",
       "      <td>0.562219</td>\n",
       "      <td>-0.384457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.808169</td>\n",
       "      <td>-0.100501</td>\n",
       "      <td>0.070874</td>\n",
       "      <td>-1.263148</td>\n",
       "      <td>-0.236435</td>\n",
       "      <td>-0.306272</td>\n",
       "      <td>-0.231552</td>\n",
       "      <td>-0.270539</td>\n",
       "      <td>-0.466494</td>\n",
       "      <td>-0.134966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.028254</td>\n",
       "      <td>-0.417425</td>\n",
       "      <td>-0.146809</td>\n",
       "      <td>-1.318120</td>\n",
       "      <td>-0.382460</td>\n",
       "      <td>-0.310825</td>\n",
       "      <td>-0.373750</td>\n",
       "      <td>-0.273281</td>\n",
       "      <td>-0.145021</td>\n",
       "      <td>-0.353907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.454660</td>\n",
       "      <td>-0.023920</td>\n",
       "      <td>-0.147297</td>\n",
       "      <td>-0.392117</td>\n",
       "      <td>-0.165573</td>\n",
       "      <td>-0.129866</td>\n",
       "      <td>-0.163592</td>\n",
       "      <td>-0.145085</td>\n",
       "      <td>-0.278824</td>\n",
       "      <td>-0.226616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138130</td>\n",
       "      <td>0.337278</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>-0.477043</td>\n",
       "      <td>1.200599</td>\n",
       "      <td>1.272487</td>\n",
       "      <td>1.177992</td>\n",
       "      <td>0.843914</td>\n",
       "      <td>-0.852262</td>\n",
       "      <td>1.667480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    x0_Agriculture  x0_Architecture  x0_Arts  x0_Communications-Media  \\\n",
       "0              0.0              0.0      0.0                      0.0   \n",
       "1              0.0              0.0      0.0                      0.0   \n",
       "2              0.0              1.0      0.0                      0.0   \n",
       "3              0.0              0.0      0.0                      0.0   \n",
       "4              0.0              0.0      0.0                      0.0   \n",
       "..             ...              ...      ...                      ...   \n",
       "64             0.0              0.0      0.0                      0.0   \n",
       "65             0.0              0.0      0.0                      0.0   \n",
       "66             0.0              0.0      0.0                      0.0   \n",
       "67             0.0              0.0      0.0                      0.0   \n",
       "68             0.0              0.0      0.0                      0.0   \n",
       "\n",
       "    x0_Consulting  x0_Education  x0_Engineering  x0_HumanResources  \\\n",
       "0             0.0           0.0             0.0                0.0   \n",
       "1             0.0           0.0             0.0                0.0   \n",
       "2             0.0           0.0             0.0                0.0   \n",
       "3             0.0           0.0             0.0                0.0   \n",
       "4             0.0           0.0             0.0                0.0   \n",
       "..            ...           ...             ...                ...   \n",
       "64            0.0           0.0             0.0                0.0   \n",
       "65            0.0           0.0             0.0                0.0   \n",
       "66            0.0           0.0             0.0                0.0   \n",
       "67            0.0           0.0             0.0                0.0   \n",
       "68            0.0           0.0             0.0                0.0   \n",
       "\n",
       "    x0_Internet  x0_Law  ...  Symbol ratio  Average letters per word  \\\n",
       "0           0.0     0.0  ...     -1.188966                 -0.211855   \n",
       "1           0.0     0.0  ...     -0.760447                 -0.032599   \n",
       "2           0.0     0.0  ...     -1.699487                 -0.251692   \n",
       "3           0.0     0.0  ...      0.733598                 -0.806096   \n",
       "4           0.0     0.0  ...     -0.655676                  0.026087   \n",
       "..          ...     ...  ...           ...                       ...   \n",
       "64          0.0     0.0  ...      1.536923                  0.602167   \n",
       "65          0.0     0.0  ...     -0.808169                 -0.100501   \n",
       "66          0.0     0.0  ...      1.028254                 -0.417425   \n",
       "67          0.0     0.0  ...     -0.454660                 -0.023920   \n",
       "68          0.0     0.0  ...     -0.138130                  0.337278   \n",
       "\n",
       "    Variance of letters per word  Unique words ratio  \\\n",
       "0                      -0.141969            0.249935   \n",
       "1                      -0.199648            0.076483   \n",
       "2                      -0.255734            1.601238   \n",
       "3                      -0.252732            0.099943   \n",
       "4                      -0.126142            1.362211   \n",
       "..                           ...                 ...   \n",
       "64                      0.203957           -0.927789   \n",
       "65                      0.070874           -1.263148   \n",
       "66                     -0.146809           -1.318120   \n",
       "67                     -0.147297           -0.392117   \n",
       "68                      0.004921           -0.477043   \n",
       "\n",
       "    Average letters per sentence  Variance of letters per sentence  \\\n",
       "0                      -0.109786                         -0.209599   \n",
       "1                      -0.321340                         -0.309126   \n",
       "2                       0.097803                         -0.399956   \n",
       "3                      -0.421116                         -0.374826   \n",
       "4                       0.977000                         -0.399956   \n",
       "..                           ...                               ...   \n",
       "64                      1.000337                          5.946264   \n",
       "65                     -0.236435                         -0.306272   \n",
       "66                     -0.382460                         -0.310825   \n",
       "67                     -0.165573                         -0.129866   \n",
       "68                      1.200599                          1.272487   \n",
       "\n",
       "    Average words per sentence  Variance of words per sentence  \\\n",
       "0                    -0.100388                       -0.235177   \n",
       "1                    -0.327829                       -0.285257   \n",
       "2                     0.048626                       -0.353575   \n",
       "3                    -0.407464                       -0.328854   \n",
       "4                     0.958393                       -0.353575   \n",
       "..                         ...                             ...   \n",
       "64                    0.917610                        3.613456   \n",
       "65                   -0.231552                       -0.270539   \n",
       "66                   -0.373750                       -0.273281   \n",
       "67                   -0.163592                       -0.145085   \n",
       "68                    1.177992                        0.843914   \n",
       "\n",
       "    Maximal uppercase ratio per sentence  \\\n",
       "0                              -0.258180   \n",
       "1                              -0.321831   \n",
       "2                              -0.788451   \n",
       "3                              -0.852262   \n",
       "4                              -0.694032   \n",
       "..                                   ...   \n",
       "64                              0.562219   \n",
       "65                             -0.466494   \n",
       "66                             -0.145021   \n",
       "67                             -0.278824   \n",
       "68                             -0.852262   \n",
       "\n",
       "    Length of the maximal uppercase ratio sentence  \n",
       "0                                         0.348741  \n",
       "1                                        -0.333540  \n",
       "2                                         0.262183  \n",
       "3                                        -0.175699  \n",
       "4                                         1.087031  \n",
       "..                                             ...  \n",
       "64                                       -0.384457  \n",
       "65                                       -0.134966  \n",
       "66                                       -0.353907  \n",
       "67                                       -0.226616  \n",
       "68                                        1.667480  \n",
       "\n",
       "[69 rows x 47 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_data = stacking.X_train_numerical_transformed\n",
    "numerical_features = np.append(stacking.numerical_transformer.transformers_[0][1].get_feature_names(),\\\n",
    "                     stacking.X_train_numerical.columns.drop(categorial_variables))\n",
    "\n",
    "df_numerical_cluster = pd.DataFrame(numerical_data, columns=numerical_features)\n",
    "df_numerical_cluster\n",
    "\n",
    "\n",
    "# Die Features mit den x0 - xi Werten beschreiben die Ausprägungen die kategorialen Variablen\n",
    "# das jeweilige i beschreibt das i-te Element der im Punkt \"Target Variable\" definierten liste categorial_variables\n",
    "# Die verbleibenden Features (ohne xi) sind Standardskaliert, (x - \\mu)/\\sigma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
