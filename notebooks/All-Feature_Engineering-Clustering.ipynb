{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# universally modules\n",
    "import re\n",
    "import sys\n",
    "import regex\n",
    "import nltk.data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "# preprocessing and transformation modules\n",
    "import fasttext\n",
    "import Preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# model algorithm\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "# evaluation modules\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to speed up the process choose a sample size to randomly draw a sample of the whole daataset\n",
    "sample_size = 100_000\n",
    "\n",
    "# remove all text that contain less than n chars\n",
    "min_chars_per_text = 50\n",
    "\n",
    "# which features will be used for the TF-IDF transformation\n",
    "text_features = \"text_preprocessed\"\n",
    "\n",
    "# set directory where data is stored\n",
    "\n",
    "data_directory = \"../../data/\"\n",
    "\n",
    "#### define the target variable and categorial variables used in later transformations ###\n",
    "#### Case 1: gender \n",
    "#target_variable = \"gender\"\n",
    "#categorial_variables =  [\"topic\", \"sign\"]\n",
    "\n",
    "# Case 2: topic\n",
    "#target_variable = \"topic\"\n",
    "#categorial_variables =  [\"gender\", \"sign\"]\n",
    "\n",
    "# Case 3: age\n",
    "#target_variable = \"age\"\n",
    "#categorial_variables =  [\"topic\", \"gender\", \"sign\"]\n",
    "\n",
    "# Case 4: sign\n",
    "#target_variable = \"sign\"\n",
    "#categorial_variables =  [\"gender\", \"topic\"]\n",
    "\n",
    "# Case 5: all\n",
    "target_variable = \"all\"\n",
    "categorial_variables =  [\"topic\", \"gender\", \"sign\"]\n",
    "############################################################################################\n",
    "\n",
    "# use only words that occur at least sqrt_3(X) times \n",
    "min_df_exponent = (1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "df = pd.read_csv(data_directory + \"blogtext.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240436</th>\n",
       "      <td>1058543</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>02,August,2004</td>\n",
       "      <td>1 Corinthians 5:11 'But now I have wri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54139</th>\n",
       "      <td>3440336</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>08,July,2004</td>\n",
       "      <td>Having moved to Jersey City nearly a mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637911</th>\n",
       "      <td>3546243</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>02,July,2004</td>\n",
       "      <td>urlLink Hey, Metro! Need To Save...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61178</th>\n",
       "      <td>3367064</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>29,July,2004</td>\n",
       "      <td>The most hilarious movie I have s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314089</th>\n",
       "      <td>3590478</td>\n",
       "      <td>female</td>\n",
       "      <td>34</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>20,April,2004</td>\n",
       "      <td>Short of being attached to the b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25853</th>\n",
       "      <td>1939766</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>25,January,2004</td>\n",
       "      <td>How did this happen? Yesterday I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34366</th>\n",
       "      <td>2781841</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>07,May,2004</td>\n",
       "      <td>I've been thinking about language lately, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177814</th>\n",
       "      <td>3567033</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>urlLink    I was able to get up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606589</th>\n",
       "      <td>3353160</td>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Leo</td>\n",
       "      <td>07,June,2004</td>\n",
       "      <td>Sorry again about that, but i've be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503002</th>\n",
       "      <td>2824507</td>\n",
       "      <td>male</td>\n",
       "      <td>26</td>\n",
       "      <td>Government</td>\n",
       "      <td>Libra</td>\n",
       "      <td>25,June,2004</td>\n",
       "      <td>urlLink    Dick Zigun, Found...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  gender  age       topic         sign             date  \\\n",
       "240436  1058543  female   24      indUnk  Sagittarius   02,August,2004   \n",
       "54139   3440336  female   23        Arts        Virgo     08,July,2004   \n",
       "637911  3546243  female   24      indUnk       Taurus     02,July,2004   \n",
       "61178   3367064  female   26      indUnk       Taurus     29,July,2004   \n",
       "314089  3590478  female   34  Technology    Capricorn    20,April,2004   \n",
       "...         ...     ...  ...         ...          ...              ...   \n",
       "25853   1939766  female   23        Arts     Aquarius  25,January,2004   \n",
       "34366   2781841  female   23     Student       Pisces      07,May,2004   \n",
       "177814  3567033    male   25      indUnk       Gemini     01,July,2004   \n",
       "606589  3353160  female   14        Arts          Leo     07,June,2004   \n",
       "503002  2824507    male   26  Government        Libra     25,June,2004   \n",
       "\n",
       "                                                     text  \n",
       "240436          1 Corinthians 5:11 'But now I have wri...  \n",
       "54139          Having moved to Jersey City nearly a mo...  \n",
       "637911                urlLink Hey, Metro! Need To Save...  \n",
       "61178                The most hilarious movie I have s...  \n",
       "314089                Short of being attached to the b...  \n",
       "...                                                   ...  \n",
       "25853                How did this happen? Yesterday I ...  \n",
       "34366      I've been thinking about language lately, w...  \n",
       "177814                urlLink    I was able to get up ...  \n",
       "606589             Sorry again about that, but i've be...  \n",
       "503002                    urlLink    Dick Zigun, Found...  \n",
       "\n",
       "[100000 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw random sample for faster processing:\n",
    "df = df.sample(sample_size, random_state=42)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for a mininmal number of letters in a tweet:\n",
    "df = df[df[\"text\"].str.count(r\"[a-zA-Z]\") >= min_chars_per_text]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def findDates(text):\n",
    "#    try:\n",
    "#        return len([date for date in\\\n",
    "#                    datefinder.find_dates(text)])\n",
    "#    except:\n",
    "#        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildFeatures(text):\n",
    "    text_split = text.split()\n",
    "    len_text = len(text)\n",
    "    sentence_split = tokenizer.tokenize(text)\n",
    "    \n",
    "    # find the number of urls in the text\n",
    "    keywords = [\"urlLink\",\"http\",\"www\"]\n",
    "    nb_urls = sum((any(keyword in pattern for keyword in keywords))\\\n",
    "               for pattern in text.split())\n",
    "    # find the number of mails in the text\n",
    "    nb_mails = len(re.findall(r\"([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+|\\bmail\\b)\"\\\n",
    "                      ,text))\n",
    "    \n",
    "    # find the number of dates in the text\n",
    "#    nb_dates = findDates(text)\n",
    "     \n",
    "    # find characteristics about the usage of letters, numbers and symbols\n",
    "    uppercase_ratio = len(re.findall(r'[A-Z]', text))/len_text\n",
    "    lowercase_ratio = len(re.findall(r'[a-z]', text))/len_text\n",
    "    number_ratio = len(re.findall(r'[0-9]', text))/len_text\n",
    "    symbol_ratio = len(re.findall(r'[$-/:-?{-~!\"^_`\\[\\]]', text))/len_text\n",
    "\n",
    "    # find characteristics about the letters per word\n",
    "    sentence_len_word = [len(word) for word in text_split]\n",
    "    avg_letters_per_word = np.mean([len(word) for word in text_split])\n",
    "    var_letters_per_word = np.var([len(word) for word in text_split])\n",
    "    unique_words_ratio = len(set(text_split))/len(text_split)\n",
    "\n",
    "    # find characteristics about the letters per sentence\n",
    "    sentence_len_list = [len(sentence) for sentence in sentence_split]\n",
    "    avg_letters_per_sentence = np.mean(sentence_len_list)\n",
    "    var_letters_per_sentence = np.var(sentence_len_list)\n",
    "    \n",
    "    # find characteristics about the words per sentence\n",
    "    words_per_sentence_len_list = [len(sentence.split()) for sentence in sentence_split]\n",
    "    avg_words_per_sentence = np.mean(words_per_sentence_len_list)\n",
    "    var_words_per_sentence = np.var(words_per_sentence_len_list)\n",
    "    \n",
    "    # find the trumps\n",
    "    uppercase_per_sentence_ratio = [len(re.findall(r'[A-Z]', sentence))/len(sentence)\\\n",
    "                                    for sentence in sentence_split]\n",
    "    max_sentence_uppercase_ratio = max(uppercase_per_sentence_ratio)\n",
    "    max_sentence_uppercase_len = len(sentence_split[uppercase_per_sentence_ratio.index(max_sentence_uppercase_ratio)])\n",
    "    \n",
    "    return len_text, nb_urls, nb_mails,\\\n",
    "           uppercase_ratio, lowercase_ratio, number_ratio, symbol_ratio,\\\n",
    "           avg_letters_per_word, var_letters_per_word, unique_words_ratio,\\\n",
    "           avg_letters_per_sentence, var_letters_per_sentence,\\\n",
    "           avg_words_per_sentence, var_words_per_sentence,\\\n",
    "           max_sentence_uppercase_ratio, max_sentence_uppercase_len        \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90439/90439 [01:42<00:00, 885.30it/s] \n"
     ]
    }
   ],
   "source": [
    "# append the data\n",
    "features = [buildFeatures(text) for text  in tqdm(df[\"text\"])]\n",
    "\n",
    "# append the data\n",
    "columns = [\"Text length\", \"Number URLs\", \"Number mails\",\\\n",
    "          \"Uppercase ratio\", \"Lowercase ratio\", \"Number ratio\", \"Symbol ratio\",\\\n",
    "          \"Average letters per word\", \"Variance of letters per word\", \"Unique words ratio\",\\\n",
    "          \"Average letters per sentence\", \"Variance of letters per sentence\",\\\n",
    "          \"Average words per sentence\", \"Variance of words per sentence\",\\\n",
    "          \"Maximal uppercase ratio per sentence\", \"Length of the maximal uppercase ratio sentence\"]\n",
    "\n",
    "# merge the features with the original dataset\n",
    "df_preprocessed = df.merge(pd.DataFrame(features, columns=columns), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90439/90439 [36:57<00:00, 40.79it/s]  \n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90439/90439 [00:14<00:00, 6430.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# use the preprocessing  module\n",
    "preprocessor = Preprocessing.Preprocessing()\n",
    "df_preprocessed[\"text_preprocessed\"] = preprocessor.ProcessMany(df_preprocessed[\"text\"])\n",
    "\n",
    "# predict the main language\n",
    "model = fasttext.load_model('../src/data/lid.176.ftz')\n",
    "df_preprocessed[\"main_language\"] = [model.predict(text)[0][0].split(\"__\")[-1] for text in tqdm(df_preprocessed[\"text_preprocessed\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii_words(text):\n",
    "    return \"\".join([f\"{word} \" for word in text.split() if len(re.findall(r'[^\\x00-\\x7f]', word)) == 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecassary features\n",
    "df_filtered = df_preprocessed[(df_preprocessed[\"main_language\"] == \"en\")]\\\n",
    "                .drop([\"id\",\"text\",\"date\",\"main_language\"], axis= 1)\n",
    "\n",
    "# remove all words with non-ascii chars\n",
    "df_filtered[\"text_preprocessed\"] = df_filtered[\"text_preprocessed\"].apply(remove_non_ascii_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>Text length</th>\n",
       "      <th>Number URLs</th>\n",
       "      <th>Number mails</th>\n",
       "      <th>Uppercase ratio</th>\n",
       "      <th>Lowercase ratio</th>\n",
       "      <th>Number ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>Average letters per word</th>\n",
       "      <th>Variance of letters per word</th>\n",
       "      <th>Unique words ratio</th>\n",
       "      <th>Average letters per sentence</th>\n",
       "      <th>Variance of letters per sentence</th>\n",
       "      <th>Average words per sentence</th>\n",
       "      <th>Variance of words per sentence</th>\n",
       "      <th>Maximal uppercase ratio per sentence</th>\n",
       "      <th>Length of the maximal uppercase ratio sentence</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>826</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024213</td>\n",
       "      <td>0.713075</td>\n",
       "      <td>0.004843</td>\n",
       "      <td>...</td>\n",
       "      <td>4.082803</td>\n",
       "      <td>5.642825</td>\n",
       "      <td>0.687898</td>\n",
       "      <td>66.166667</td>\n",
       "      <td>3770.972222</td>\n",
       "      <td>13.083333</td>\n",
       "      <td>128.409722</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>1 corinthians 5:11 ' but -pron- write company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>2666</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028132</td>\n",
       "      <td>0.746437</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>...</td>\n",
       "      <td>4.378049</td>\n",
       "      <td>5.804234</td>\n",
       "      <td>0.623984</td>\n",
       "      <td>105.120000</td>\n",
       "      <td>3962.745600</td>\n",
       "      <td>19.680000</td>\n",
       "      <td>124.777600</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>15</td>\n",
       "      <td>move jersey city a month ago -pron- idea -pron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>269</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040892</td>\n",
       "      <td>0.665428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>6.247934</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>50.600000</td>\n",
       "      <td>1954.640000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>84.960000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>19</td>\n",
       "      <td>hey metro save money a hike heel fare hike yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>1756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015945</td>\n",
       "      <td>0.763667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.580645</td>\n",
       "      <td>6.153174</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>78.227273</td>\n",
       "      <td>1352.721074</td>\n",
       "      <td>14.090909</td>\n",
       "      <td>45.900826</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>18</td>\n",
       "      <td>hilarious movie -pron- year a comedy movie abs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>34</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>9046</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037917</td>\n",
       "      <td>0.742096</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>...</td>\n",
       "      <td>4.719287</td>\n",
       "      <td>6.343224</td>\n",
       "      <td>0.550605</td>\n",
       "      <td>112.936709</td>\n",
       "      <td>4624.844095</td>\n",
       "      <td>19.898734</td>\n",
       "      <td>144.420125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>60</td>\n",
       "      <td>short attach bumper a pickup truck a cock ring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90434</th>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032841</td>\n",
       "      <td>0.715928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.157895</td>\n",
       "      <td>5.483841</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>59.100000</td>\n",
       "      <td>1282.090000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>43.240000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>19</td>\n",
       "      <td>happen yesterday -pron- mall store -pron- visi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90435</th>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>4006</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020969</td>\n",
       "      <td>0.742636</td>\n",
       "      <td>0.009735</td>\n",
       "      <td>...</td>\n",
       "      <td>4.484722</td>\n",
       "      <td>8.055322</td>\n",
       "      <td>0.469444</td>\n",
       "      <td>98.200000</td>\n",
       "      <td>5066.410000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>182.650000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>8</td>\n",
       "      <td>-pron- ' ve think language good -pron- ' m maj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90436</th>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022161</td>\n",
       "      <td>0.709141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.138462</td>\n",
       "      <td>5.534675</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>402.888889</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>29.555556</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>125</td>\n",
       "      <td>-pron- fish poudre river a saturday morning -p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90437</th>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Leo</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.701531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.140845</td>\n",
       "      <td>4.261853</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>74.200000</td>\n",
       "      <td>1987.760000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>51.760000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>48</td>\n",
       "      <td>i ' ve shut room past day live water completel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90438</th>\n",
       "      <td>male</td>\n",
       "      <td>26</td>\n",
       "      <td>Government</td>\n",
       "      <td>Libra</td>\n",
       "      <td>149</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.080537</td>\n",
       "      <td>0.543624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.533333</td>\n",
       "      <td>9.448889</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090226</td>\n",
       "      <td>133</td>\n",
       "      <td>dick zigun founder mermaid parade marty markow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88390 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender  age       topic         sign  Text length  Number URLs  \\\n",
       "0      female   24      indUnk  Sagittarius          826            0   \n",
       "1      female   23        Arts        Virgo         2666            0   \n",
       "2      female   24      indUnk       Taurus          269            1   \n",
       "3      female   26      indUnk       Taurus         1756            0   \n",
       "4      female   34  Technology    Capricorn         9046            0   \n",
       "...       ...  ...         ...          ...          ...          ...   \n",
       "90434  female   23        Arts     Aquarius          609            0   \n",
       "90435  female   23     Student       Pisces         4006            5   \n",
       "90436    male   25      indUnk       Gemini          361            2   \n",
       "90437  female   14        Arts          Leo          392            0   \n",
       "90438    male   26  Government        Libra          149            2   \n",
       "\n",
       "       Number mails  Uppercase ratio  Lowercase ratio  Number ratio  ...  \\\n",
       "0                 0         0.024213         0.713075      0.004843  ...   \n",
       "1                 0         0.028132         0.746437      0.002626  ...   \n",
       "2                 0         0.040892         0.665428      0.000000  ...   \n",
       "3                 0         0.015945         0.763667      0.000000  ...   \n",
       "4                 0         0.037917         0.742096      0.003648  ...   \n",
       "...             ...              ...              ...           ...  ...   \n",
       "90434             0         0.032841         0.715928      0.000000  ...   \n",
       "90435             0         0.020969         0.742636      0.009735  ...   \n",
       "90436             0         0.022161         0.709141      0.000000  ...   \n",
       "90437             0         0.020408         0.701531      0.000000  ...   \n",
       "90438             0         0.080537         0.543624      0.000000  ...   \n",
       "\n",
       "       Average letters per word  Variance of letters per word  \\\n",
       "0                      4.082803                      5.642825   \n",
       "1                      4.378049                      5.804234   \n",
       "2                      4.545455                      6.247934   \n",
       "3                      4.580645                      6.153174   \n",
       "4                      4.719287                      6.343224   \n",
       "...                         ...                           ...   \n",
       "90434                  4.157895                      5.483841   \n",
       "90435                  4.484722                      8.055322   \n",
       "90436                  4.138462                      5.534675   \n",
       "90437                  4.140845                      4.261853   \n",
       "90438                  6.533333                      9.448889   \n",
       "\n",
       "       Unique words ratio  Average letters per sentence  \\\n",
       "0                0.687898                     66.166667   \n",
       "1                0.623984                    105.120000   \n",
       "2                0.909091                     50.600000   \n",
       "3                0.632258                     78.227273   \n",
       "4                0.550605                    112.936709   \n",
       "...                   ...                           ...   \n",
       "90434            0.666667                     59.100000   \n",
       "90435            0.469444                     98.200000   \n",
       "90436            0.723077                    116.666667   \n",
       "90437            0.845070                     74.200000   \n",
       "90438            0.933333                    133.000000   \n",
       "\n",
       "       Variance of letters per sentence  Average words per sentence  \\\n",
       "0                           3770.972222                   13.083333   \n",
       "1                           3962.745600                   19.680000   \n",
       "2                           1954.640000                    8.800000   \n",
       "3                           1352.721074                   14.090909   \n",
       "4                           4624.844095                   19.898734   \n",
       "...                                 ...                         ...   \n",
       "90434                       1282.090000                   11.400000   \n",
       "90435                       5066.410000                   18.000000   \n",
       "90436                        402.888889                   21.666667   \n",
       "90437                       1987.760000                   14.200000   \n",
       "90438                          0.000000                   15.000000   \n",
       "\n",
       "       Variance of words per sentence  Maximal uppercase ratio per sentence  \\\n",
       "0                          128.409722                              0.166667   \n",
       "1                          124.777600                              0.133333   \n",
       "2                           84.960000                              0.210526   \n",
       "3                           45.900826                              0.055556   \n",
       "4                          144.420125                              0.333333   \n",
       "...                               ...                                   ...   \n",
       "90434                       43.240000                              0.105263   \n",
       "90435                      182.650000                              0.125000   \n",
       "90436                       29.555556                              0.040000   \n",
       "90437                       51.760000                              0.062500   \n",
       "90438                        0.000000                              0.090226   \n",
       "\n",
       "       Length of the maximal uppercase ratio sentence  \\\n",
       "0                                                   6   \n",
       "1                                                  15   \n",
       "2                                                  19   \n",
       "3                                                  18   \n",
       "4                                                  60   \n",
       "...                                               ...   \n",
       "90434                                              19   \n",
       "90435                                               8   \n",
       "90436                                             125   \n",
       "90437                                              48   \n",
       "90438                                             133   \n",
       "\n",
       "                                       text_preprocessed  \n",
       "0      1 corinthians 5:11 ' but -pron- write company ...  \n",
       "1      move jersey city a month ago -pron- idea -pron...  \n",
       "2      hey metro save money a hike heel fare hike yea...  \n",
       "3      hilarious movie -pron- year a comedy movie abs...  \n",
       "4      short attach bumper a pickup truck a cock ring...  \n",
       "...                                                  ...  \n",
       "90434  happen yesterday -pron- mall store -pron- visi...  \n",
       "90435  -pron- ' ve think language good -pron- ' m maj...  \n",
       "90436  -pron- fish poudre river a saturday morning -p...  \n",
       "90437  i ' ve shut room past day live water completel...  \n",
       "90438  dick zigun founder mermaid parade marty markow...  \n",
       "\n",
       "[88390 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the preprocessed data before removing the \"original\" taxt, to interpret the clusters later\n",
    "df_filtered.to_csv(data_directory + f'bolgtext_filtered.csv', index = False)\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedTransformation:\n",
    "    \n",
    "    def  __init__(self, X=None, y=None, numerical_transformer=None, text_transformer=None, text_features=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.numerical_transformer = numerical_transformer\n",
    "        self.text_transformer = text_transformer\n",
    "        self.text_features = text_features\n",
    "        \n",
    "    def data_split(self, X, y, test_size= 0.2):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = X, X, y, y\n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "        \n",
    "    def build_transformer(self, X=None, y=None,\\\n",
    "                          numerical_transformer=None, text_transformer=None, text_features=None):\n",
    "        # check if variables are present\n",
    "        if X == None:\n",
    "            X = self.X\n",
    "        if y == None:\n",
    "            y = self.y\n",
    "        if numerical_transformer == None:\n",
    "            numerical_transformer = self.numerical_transformer\n",
    "        if text_transformer == None:\n",
    "            text_transformer = self.text_transformer\n",
    "        if text_features == None:\n",
    "            text_features = self.text_features\n",
    "\n",
    "        # split the data\n",
    "        \n",
    "        self.data_split(X, y)\n",
    "        \n",
    "        # Create datasets for each classifier\n",
    "        self.X_train_text = self.X_train[text_features]\n",
    "        self.X_test_text =  self.X_test[text_features]\n",
    "        \n",
    "        self.X_train_numerical = self.X_train.drop(text_features, axis=1)\n",
    "        self.X_test_numerical = self.X_test.drop(text_features, axis=1)\n",
    "\n",
    "        # create transformers \n",
    "        self.numerical_transformer = numerical_transformer\n",
    "        self.text_transformer = text_transformer\n",
    "        \n",
    "        #create transformed training batches\n",
    "        self.X_train_numerical_transformed = self.numerical_transformer.fit_transform(self.X_train_numerical)\n",
    "        self.X_test_numerical_transformed = self.numerical_transformer.transform(self.X_test_numerical)\n",
    "\n",
    "        self.X_train_text_transformed = self.text_transformer.fit_transform(self.X_train_text)\n",
    "        self.X_test_text_transformed = self.text_transformer.transform(self.X_test_text)\n",
    "\n",
    "    def transform_one(self, text):\n",
    "        entry = pd.DataFrame(columns=text.keys())\n",
    "        entry = entry.append(text, ignore_index=True)\n",
    "        \n",
    "        # create datasets for each transformer\n",
    "        entry_text = entry[text_features]\n",
    "        entry_numerical = entry.drop(text_features, axis=1)\n",
    "        \n",
    "        entry_numerical_transformed = self.numerical_transformer.transform(entry_numerical)\n",
    "        entry_text_transformed = self.text_transformer.transform(entry_text)\n",
    "        \n",
    "        return {\"transformed_text\": entry_text_transformed,\\\n",
    "               \"transformed_numerical\": entry_numerical_transformed}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X,y = df_filtered.drop(target_variable, axis=1),df_filtered[target_variable]\n",
    "X,y = df_filtered,df_filtered[\"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text transformer finished\n",
      "numerical transformer finished\n",
      "stacking created\n",
      "stacking finished\n"
     ]
    }
   ],
   "source": [
    "# use the  text transformer class to create two transformers for the textual and the numerical model\n",
    "text_transformer = TfidfVectorizer(ngram_range=(1,1), min_df=int(len(X)**(min_df_exponent)))\n",
    "print('text transformer finished')\n",
    "\n",
    "numerical_transformer = make_column_transformer((OneHotEncoder(handle_unknown=\"ignore\"), categorial_variables)\\\n",
    "                                                       , remainder=StandardScaler())\n",
    "print('numerical transformer finished')\n",
    "\n",
    "stacking = StackedTransformation(X, y, numerical_transformer, text_transformer, text_features)\n",
    "print('stacking created')\n",
    "\n",
    "stacking.build_transformer()\n",
    "print('stacking finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00am</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>...</th>\n",
       "      <th>zen</th>\n",
       "      <th>zeppelin</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033552</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88385</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88386</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88387</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88388</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88389</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88390 rows Ã— 11436 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  000  00am  00pm   01   02   03   04   05   06  ...  zen  zeppelin  \\\n",
       "0      0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0       0.0   \n",
       "1      0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0       0.0   \n",
       "2      0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0       0.0   \n",
       "3      0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0       0.0   \n",
       "4      0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0       0.0   \n",
       "...    ...  ...   ...   ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
       "88385  0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0       0.0   \n",
       "88386  0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0       0.0   \n",
       "88387  0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0       0.0   \n",
       "88388  0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0       0.0   \n",
       "88389  0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0       0.0   \n",
       "\n",
       "       zero  zip  zodiac  zoe  zombie  zone       zoo  zoom  \n",
       "0       0.0  0.0     0.0  0.0     0.0   0.0  0.000000   0.0  \n",
       "1       0.0  0.0     0.0  0.0     0.0   0.0  0.000000   0.0  \n",
       "2       0.0  0.0     0.0  0.0     0.0   0.0  0.000000   0.0  \n",
       "3       0.0  0.0     0.0  0.0     0.0   0.0  0.000000   0.0  \n",
       "4       0.0  0.0     0.0  0.0     0.0   0.0  0.033552   0.0  \n",
       "...     ...  ...     ...  ...     ...   ...       ...   ...  \n",
       "88385   0.0  0.0     0.0  0.0     0.0   0.0  0.000000   0.0  \n",
       "88386   0.0  0.0     0.0  0.0     0.0   0.0  0.000000   0.0  \n",
       "88387   0.0  0.0     0.0  0.0     0.0   0.0  0.000000   0.0  \n",
       "88388   0.0  0.0     0.0  0.0     0.0   0.0  0.000000   0.0  \n",
       "88389   0.0  0.0     0.0  0.0     0.0   0.0  0.000000   0.0  \n",
       "\n",
       "[88390 rows x 11436 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features = stacking.text_transformer.get_feature_names()\n",
    "text_data = stacking.X_train_text_transformed.toarray()\n",
    "\n",
    "df_text_cluster = pd.DataFrame(text_data, columns=text_features)\n",
    "df_text_cluster\n",
    "\n",
    "# Die Features beschreiben die Worte im Text\n",
    "# Die Werte sind die TF*IDF-transformierten Textdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_Accounting</th>\n",
       "      <th>x0_Advertising</th>\n",
       "      <th>x0_Agriculture</th>\n",
       "      <th>x0_Architecture</th>\n",
       "      <th>x0_Arts</th>\n",
       "      <th>x0_Automotive</th>\n",
       "      <th>x0_Banking</th>\n",
       "      <th>x0_Biotech</th>\n",
       "      <th>x0_BusinessServices</th>\n",
       "      <th>x0_Chemicals</th>\n",
       "      <th>...</th>\n",
       "      <th>Symbol ratio</th>\n",
       "      <th>Average letters per word</th>\n",
       "      <th>Variance of letters per word</th>\n",
       "      <th>Unique words ratio</th>\n",
       "      <th>Average letters per sentence</th>\n",
       "      <th>Variance of letters per sentence</th>\n",
       "      <th>Average words per sentence</th>\n",
       "      <th>Variance of words per sentence</th>\n",
       "      <th>Maximal uppercase ratio per sentence</th>\n",
       "      <th>Length of the maximal uppercase ratio sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.406886</td>\n",
       "      <td>-0.185619</td>\n",
       "      <td>-0.024471</td>\n",
       "      <td>-0.381103</td>\n",
       "      <td>-0.291581</td>\n",
       "      <td>-0.046192</td>\n",
       "      <td>-0.244946</td>\n",
       "      <td>-0.048985</td>\n",
       "      <td>-0.002707</td>\n",
       "      <td>-0.432317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.528082</td>\n",
       "      <td>-0.066584</td>\n",
       "      <td>-0.023874</td>\n",
       "      <td>-0.837267</td>\n",
       "      <td>-0.045730</td>\n",
       "      <td>-0.044673</td>\n",
       "      <td>-0.011748</td>\n",
       "      <td>-0.050032</td>\n",
       "      <td>-0.167852</td>\n",
       "      <td>-0.383229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280450</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>-0.022233</td>\n",
       "      <td>1.197579</td>\n",
       "      <td>-0.389829</td>\n",
       "      <td>-0.060585</td>\n",
       "      <td>-0.396366</td>\n",
       "      <td>-0.061504</td>\n",
       "      <td>0.214590</td>\n",
       "      <td>-0.361412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.594240</td>\n",
       "      <td>0.015097</td>\n",
       "      <td>-0.022583</td>\n",
       "      <td>-0.778212</td>\n",
       "      <td>-0.215462</td>\n",
       "      <td>-0.065355</td>\n",
       "      <td>-0.209328</td>\n",
       "      <td>-0.072757</td>\n",
       "      <td>-0.553193</td>\n",
       "      <td>-0.366866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.384038</td>\n",
       "      <td>0.070993</td>\n",
       "      <td>-0.021881</td>\n",
       "      <td>-1.360983</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>-0.039426</td>\n",
       "      <td>-0.004016</td>\n",
       "      <td>-0.044372</td>\n",
       "      <td>0.823022</td>\n",
       "      <td>-0.137788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88385</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.574430</td>\n",
       "      <td>-0.155344</td>\n",
       "      <td>-0.025058</td>\n",
       "      <td>-0.532634</td>\n",
       "      <td>-0.336182</td>\n",
       "      <td>-0.065915</td>\n",
       "      <td>-0.304453</td>\n",
       "      <td>-0.073524</td>\n",
       "      <td>-0.306923</td>\n",
       "      <td>-0.361412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88386</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.453092</td>\n",
       "      <td>-0.023577</td>\n",
       "      <td>-0.015550</td>\n",
       "      <td>-1.940234</td>\n",
       "      <td>-0.089405</td>\n",
       "      <td>-0.035927</td>\n",
       "      <td>-0.071138</td>\n",
       "      <td>-0.033358</td>\n",
       "      <td>-0.209139</td>\n",
       "      <td>-0.421408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88387</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.180529</td>\n",
       "      <td>-0.163179</td>\n",
       "      <td>-0.024871</td>\n",
       "      <td>-0.130027</td>\n",
       "      <td>0.027146</td>\n",
       "      <td>-0.072882</td>\n",
       "      <td>0.058482</td>\n",
       "      <td>-0.077467</td>\n",
       "      <td>-0.630261</td>\n",
       "      <td>0.216737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88388</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.632138</td>\n",
       "      <td>-0.162218</td>\n",
       "      <td>-0.029577</td>\n",
       "      <td>0.740656</td>\n",
       "      <td>-0.240880</td>\n",
       "      <td>-0.060323</td>\n",
       "      <td>-0.205471</td>\n",
       "      <td>-0.071069</td>\n",
       "      <td>-0.518787</td>\n",
       "      <td>-0.203239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88389</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.420055</td>\n",
       "      <td>0.802362</td>\n",
       "      <td>-0.010396</td>\n",
       "      <td>1.370600</td>\n",
       "      <td>0.130232</td>\n",
       "      <td>-0.076074</td>\n",
       "      <td>-0.177190</td>\n",
       "      <td>-0.085982</td>\n",
       "      <td>-0.381424</td>\n",
       "      <td>0.260371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88390 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x0_Accounting  x0_Advertising  x0_Agriculture  x0_Architecture  \\\n",
       "0                0.0             0.0             0.0              0.0   \n",
       "1                0.0             0.0             0.0              0.0   \n",
       "2                0.0             0.0             0.0              0.0   \n",
       "3                0.0             0.0             0.0              0.0   \n",
       "4                0.0             0.0             0.0              0.0   \n",
       "...              ...             ...             ...              ...   \n",
       "88385            0.0             0.0             0.0              0.0   \n",
       "88386            0.0             0.0             0.0              0.0   \n",
       "88387            0.0             0.0             0.0              0.0   \n",
       "88388            0.0             0.0             0.0              0.0   \n",
       "88389            0.0             0.0             0.0              0.0   \n",
       "\n",
       "       x0_Arts  x0_Automotive  x0_Banking  x0_Biotech  x0_BusinessServices  \\\n",
       "0          0.0            0.0         0.0         0.0                  0.0   \n",
       "1          1.0            0.0         0.0         0.0                  0.0   \n",
       "2          0.0            0.0         0.0         0.0                  0.0   \n",
       "3          0.0            0.0         0.0         0.0                  0.0   \n",
       "4          0.0            0.0         0.0         0.0                  0.0   \n",
       "...        ...            ...         ...         ...                  ...   \n",
       "88385      1.0            0.0         0.0         0.0                  0.0   \n",
       "88386      0.0            0.0         0.0         0.0                  0.0   \n",
       "88387      0.0            0.0         0.0         0.0                  0.0   \n",
       "88388      1.0            0.0         0.0         0.0                  0.0   \n",
       "88389      0.0            0.0         0.0         0.0                  0.0   \n",
       "\n",
       "       x0_Chemicals  ...  Symbol ratio  Average letters per word  \\\n",
       "0               0.0  ...     -0.406886                 -0.185619   \n",
       "1               0.0  ...     -0.528082                 -0.066584   \n",
       "2               0.0  ...     -0.280450                  0.000909   \n",
       "3               0.0  ...     -0.594240                  0.015097   \n",
       "4               0.0  ...     -0.384038                  0.070993   \n",
       "...             ...  ...           ...                       ...   \n",
       "88385           0.0  ...     -0.574430                 -0.155344   \n",
       "88386           0.0  ...     -0.453092                 -0.023577   \n",
       "88387           0.0  ...     -1.180529                 -0.163179   \n",
       "88388           0.0  ...     -0.632138                 -0.162218   \n",
       "88389           0.0  ...     -0.420055                  0.802362   \n",
       "\n",
       "       Variance of letters per word  Unique words ratio  \\\n",
       "0                         -0.024471           -0.381103   \n",
       "1                         -0.023874           -0.837267   \n",
       "2                         -0.022233            1.197579   \n",
       "3                         -0.022583           -0.778212   \n",
       "4                         -0.021881           -1.360983   \n",
       "...                             ...                 ...   \n",
       "88385                     -0.025058           -0.532634   \n",
       "88386                     -0.015550           -1.940234   \n",
       "88387                     -0.024871           -0.130027   \n",
       "88388                     -0.029577            0.740656   \n",
       "88389                     -0.010396            1.370600   \n",
       "\n",
       "       Average letters per sentence  Variance of letters per sentence  \\\n",
       "0                         -0.291581                         -0.046192   \n",
       "1                         -0.045730                         -0.044673   \n",
       "2                         -0.389829                         -0.060585   \n",
       "3                         -0.215462                         -0.065355   \n",
       "4                          0.003604                         -0.039426   \n",
       "...                             ...                               ...   \n",
       "88385                     -0.336182                         -0.065915   \n",
       "88386                     -0.089405                         -0.035927   \n",
       "88387                      0.027146                         -0.072882   \n",
       "88388                     -0.240880                         -0.060323   \n",
       "88389                      0.130232                         -0.076074   \n",
       "\n",
       "       Average words per sentence  Variance of words per sentence  \\\n",
       "0                       -0.244946                       -0.048985   \n",
       "1                       -0.011748                       -0.050032   \n",
       "2                       -0.396366                       -0.061504   \n",
       "3                       -0.209328                       -0.072757   \n",
       "4                       -0.004016                       -0.044372   \n",
       "...                           ...                             ...   \n",
       "88385                   -0.304453                       -0.073524   \n",
       "88386                   -0.071138                       -0.033358   \n",
       "88387                    0.058482                       -0.077467   \n",
       "88388                   -0.205471                       -0.071069   \n",
       "88389                   -0.177190                       -0.085982   \n",
       "\n",
       "       Maximal uppercase ratio per sentence  \\\n",
       "0                                 -0.002707   \n",
       "1                                 -0.167852   \n",
       "2                                  0.214590   \n",
       "3                                 -0.553193   \n",
       "4                                  0.823022   \n",
       "...                                     ...   \n",
       "88385                             -0.306923   \n",
       "88386                             -0.209139   \n",
       "88387                             -0.630261   \n",
       "88388                             -0.518787   \n",
       "88389                             -0.381424   \n",
       "\n",
       "       Length of the maximal uppercase ratio sentence  \n",
       "0                                           -0.432317  \n",
       "1                                           -0.383229  \n",
       "2                                           -0.361412  \n",
       "3                                           -0.366866  \n",
       "4                                           -0.137788  \n",
       "...                                               ...  \n",
       "88385                                       -0.361412  \n",
       "88386                                       -0.421408  \n",
       "88387                                        0.216737  \n",
       "88388                                       -0.203239  \n",
       "88389                                        0.260371  \n",
       "\n",
       "[88390 rows x 71 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    numerical_data = stacking.X_train_numerical_transformed.toarray()\n",
    "except:\n",
    "    numerical_data = stacking.X_train_numerical_transformed\n",
    "\n",
    "\n",
    "numerical_features = np.append(stacking.numerical_transformer.transformers_[0][1].get_feature_names(),\\\n",
    "                     stacking.X_train_numerical.columns.drop(categorial_variables))\n",
    "\n",
    "df_numerical_cluster = pd.DataFrame(numerical_data, columns=numerical_features)\n",
    "df_numerical_cluster\n",
    "\n",
    "\n",
    "# Die Features mit den x0 - xi Werten beschreiben die AusprÃ¤gungen die kategorialen Variablen\n",
    "# das jeweilige i beschreibt das i-te Element der im Punkt \"Target Variable\" definierten liste categorial_variables\n",
    "# Die verbleibenden Features (ohne xi) sind Standardskaliert, (x - \\mu)/\\sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_cluster.to_csv(data_directory + f'Data_Text_Clustering.csv', index = False)\n",
    "df_numerical_cluster.to_csv(data_directory + f'Data_Numerical_Clustering.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
