{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/anaconda3/lib/python3.8/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import pandas as pd\n",
    "import Preprocessing\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from Features import buildFeatures\n",
    "from Pipeline import BuildPipeline\n",
    "from Preprocessing import Preprocessing\n",
    "from sklearn.svm import LinearSVC, LinearSVR\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor\n",
    "\n",
    "class RequestMapper:\n",
    "    \n",
    "    def __init__(self, pipelines):\n",
    "        # storing and unpacking the pipelines\n",
    "        self.pipelines = pipelines\n",
    "        self.pipeline_mapping = {\\\"age\\\": pipelines.values[0],modelling.predict_text(tfidf_transformed_text)[0]\\n    \\n    def predict_numerical(self, target_variable, text, age=None, sign=None, gender=None, topic=None):\\n        # Build dataframe for transformer\\n        columns = self.pipeline_mapping[target_variable].transformation.X_test_numerical.columns\\n        entry = pd.DataFrame(columns=columns)\\n        \\n        data_dict = buildFeatures(text)\\n        for name, variable in zip([\\\"age\\\",\\\"sign\\\",\\\"gender\\\",\\\"topic\\\"],[age, sign, gender, topic]):\\n            if variable != None:\\n                if not name == target_variable:\\n                    data_dict[name] = variable\\n                else:\\n                    print(\\\"Error, target variable is not empty\\\")\\n                \\n            elif name != target_variable:\\n                print(\\\"Error, feature missing\\\")\\n        \\n        entry_numerical  = entry.append(data_dict, ignore_index=True)\\n        \\n        data_transformed =  self.pipeline_mapping[target_variable].\\\\\\n                                transformation.numerical_transformer.transform(entry_numerical)\\n        \\n        return self.pipeline_mapping[target_variable].modelling.predict_numerical(data_transformed)[0]\\n            \\n        \\n    def predict_weighted(self, target_variable, text, age=None, sign=None, gender=None, topic=None):\\n        # Build dataframe for transformer\\n        data_dict = buildFeatures(text)\\n        data_dict[\\\"text_preprocessed\\\"] = self.preprocessor.ProcessOne(text)\\n        for name, variable in zip([\\\"age\\\",\\\"sign\\\",\\\"gender\\\",\\\"topic\\\"],[age, sign, gender, topic]):\\n            if variable != None:\\n                if not name == target_variable:\\n                    data_dict[name] = variable\\n                else:\\n                    print(\\\"Error, target variable is not empty\\\")\\n                \\n            elif name != target_variable:\\n                print(\\\"Error, feature missing\\\")\\n        \\n        prediction = self.pipeline_mapping[target_variable].modelling.weighted_prediction(data_dict,\\\\\\n                                                                                          algo_type=self.pipeline_mapping[target_variable]\\\\\\n                                                                                          .algo_type)\\n        return prediction[0]\", \"format\": \"text\", \"mimetype\": \"text/x-python\", \"size\": 3511, \"writable\": true, \"type\": \"file\"}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "df_full_preprocessed = pd.read_pickle(\"./df_full_preprocessed.pkl\")\n",
    "# import preprocessor\n",
    "preprocessing = Preprocessing.Preprocessing()\n",
    "\n",
    "# clean / filter data\n",
    "df_full_preprocessed = df_full_preprocessed[df_full_preprocessed[\"text_preprocessed\"].str.count(r\"[a-zA-Z]\") >= 50]\n",
    "df_full_preprocessed = df_full_preprocessed.drop_duplicates(\"text_preprocessed\")\n",
    "df_full_preprocessed = df_full_preprocessed[df_full_preprocessed[\"text_preprocessed\"].apply(lambda x: len(x.split())) >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the  text transformer class to create two transformers for the textual and the numerical model\n",
    "text_transformer = TfidfVectorizer(ngram_range=(1,1), min_df=int(len(df_full_preprocessed)**(1/4)), use_idf=True)\n",
    "numerical_transformer = make_column_transformer((OneHotEncoder(handle_unknown=\"ignore\"), [\"gender\",\"topic\",\"sign\"])\\\n",
    "                                                           , remainder=StandardScaler())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "X_text = text_transformer.fit_transform(df_full_preprocessed[\"text_preprocessed\"])\n",
    "X_numerical = numerical_transformer.fit_transform(df_full_preprocessed.drop(\"text_preprocessed\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(n_neighbors=10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_text = NearestNeighbors(n_neighbors=10)\n",
    "knn_text.fit(X_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(n_neighbors=10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_numerical = NearestNeighbors(n_neighbors=10)\n",
    "knn_numerical.fit(X_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_nearest_texts(knn, vectorizer, df, text):\n",
    "    text = preprocessing.ProcessOne(text)\n",
    "    prediction = knn.kneighbors(vectorizer.transform([text]))\n",
    "    return df.iloc[prediction[1][0]]\n",
    "\n",
    "def get_k_nearest_numerical(knn, vectorizer, text, age, sign, gender, topic):\n",
    "    feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%history -g -f \"history.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"In information retrieval, tf–idf, TF*IDF, or TFIDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.[1] It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling. The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general. tf–idf is one of the most popular term-weighting schemes today. A survey conducted in 2015 showed that 83% of text-based recommender systems in digital libraries use tf–idf.[2]\n",
    "\n",
    "Variations of the tf–idf weighting scheme are often used by search engines as a central tool in scoring and ranking a document's relevance given a user query. tf–idf can be successfully used for stop-words filtering in various subject fields, including text summarization and classification.\n",
    "\n",
    "One of the simplest ranking functions is computed by summing the tf–idf for each query term; many more sophisticated ranking functions are variants of this simple mode\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information retrieval tf idf tfidf short term document frequency a numerical statistic intend reflect important a word a document a collection corpus 1 a weight factor search information retrieval text mining user modeling increase proportionally number time a word appear document offset number document corpus word help adjust fact word frequently general popular term - weight scheme today a survey conduct 2015 show 83 text - base recommender system digital library 2 variation weight scheme search engine a central tool score rank a document 's relevance a user query successfully stop - word filter subject field include text summarization classification simplest rank function compute sum query term sophisticated rank function variant simple mode \n"
     ]
    }
   ],
   "source": [
    "test = get_k_nearest_texts(knn_text, text_transformer, df_full_preprocessed, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>Text length</th>\n",
       "      <th>Number URLs</th>\n",
       "      <th>Number mails</th>\n",
       "      <th>Uppercase ratio</th>\n",
       "      <th>Lowercase ratio</th>\n",
       "      <th>Number ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>Average letters per word</th>\n",
       "      <th>Variance of letters per word</th>\n",
       "      <th>Unique words ratio</th>\n",
       "      <th>Average letters per sentence</th>\n",
       "      <th>Variance of letters per sentence</th>\n",
       "      <th>Average words per sentence</th>\n",
       "      <th>Variance of words per sentence</th>\n",
       "      <th>Maximal uppercase ratio per sentence</th>\n",
       "      <th>Length of the maximal uppercase ratio sentence</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157453</th>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>Student</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81</td>\n",
       "      <td>iiiiiiii lllloooooovvvvvvvveeeeeeeee uuuuuu aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426419</th>\n",
       "      <td>female</td>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>109</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045872</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.181818</td>\n",
       "      <td>13.966942</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>101</td>\n",
       "      <td>arneitai kathgorhmatika lhpsh apagorevmenwn ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390211</th>\n",
       "      <td>male</td>\n",
       "      <td>13</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.5</td>\n",
       "      <td>1560.25</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>80</td>\n",
       "      <td>schooooooooooooooooooooooooooooool 's outttttt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444164</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>426</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438967</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.016432</td>\n",
       "      <td>...</td>\n",
       "      <td>33.166667</td>\n",
       "      <td>111.472222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>211.0</td>\n",
       "      <td>44100.00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>30.25</td>\n",
       "      <td>0.444181</td>\n",
       "      <td>421</td>\n",
       "      <td>talklistenproblemsattireattitudebrainstorms tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40247</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118110</td>\n",
       "      <td>0.472441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>285.440000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.5</td>\n",
       "      <td>1640.25</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>99</td>\n",
       "      <td>lalalalalalalalalalalalalalalalalalalalala lal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54565</th>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>...</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>552.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>324.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>70</td>\n",
       "      <td>elo2allveteranbloggers thanx4invitingmerox.wal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88023</th>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.253125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.382353</td>\n",
       "      <td>9.118512</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>299</td>\n",
       "      <td>wisteria wisteria wisteria wisteria wisteria w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570141</th>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>RealEstate</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.745283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97</td>\n",
       "      <td>ninehoursofschool twodaysaweek foranentireseme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334264</th>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.969305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>6.727273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>618</td>\n",
       "      <td>brandonbiebelbrianandersonmccrankerickostonpau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55870</th>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Military</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>2737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.892948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2726.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2733.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2733</td>\n",
       "      <td>lglhfljfljhgkl jlh ljh lkjlkclglhfljfljhgkl jl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        gender  age       topic         sign  Text length  Number URLs  \\\n",
       "157453  female   14     Student    Capricorn           89            0   \n",
       "426419  female   33      indUnk    Capricorn          109            2   \n",
       "390211    male   13      indUnk       Pisces           90            0   \n",
       "444164    male   15     Student    Capricorn          426            0   \n",
       "40247     male   15      indUnk    Capricorn          127            0   \n",
       "54565     male   23      indUnk  Sagittarius          114            0   \n",
       "88023   female   23      indUnk    Capricorn          320            0   \n",
       "570141  female   24  RealEstate    Capricorn          106            0   \n",
       "334264    male   14      indUnk     Aquarius          619            0   \n",
       "55870     male   25    Military        Virgo         2737            0   \n",
       "\n",
       "        Number mails  Uppercase ratio  Lowercase ratio  Number ratio  ...  \\\n",
       "157453             0         0.000000         0.651685      0.000000  ...   \n",
       "426419             0         0.045872         0.678899      0.000000  ...   \n",
       "390211             0         0.577778         0.000000      0.000000  ...   \n",
       "444164             0         0.438967         0.464789      0.016432  ...   \n",
       "40247              0         0.118110         0.472441      0.000000  ...   \n",
       "54565              0         0.008772         0.719298      0.026316  ...   \n",
       "88023              0         0.021875         0.253125      0.000000  ...   \n",
       "570141             0         0.000000         0.745283      0.000000  ...   \n",
       "334264             0         0.000000         0.969305      0.000000  ...   \n",
       "55870              0         0.000000         0.892948      0.000000  ...   \n",
       "\n",
       "        Average letters per word  Variance of letters per word  \\\n",
       "157453                 15.000000                     67.500000   \n",
       "426419                  7.181818                     13.966942   \n",
       "390211                 33.500000                      6.250000   \n",
       "444164                 33.166667                    111.472222   \n",
       "40247                  21.400000                    285.440000   \n",
       "54565                  46.500000                    552.250000   \n",
       "88023                   6.382353                      9.118512   \n",
       "570141                 86.000000                      0.000000   \n",
       "334264                 55.000000                      6.727273   \n",
       "55870                2726.000000                      0.000000   \n",
       "\n",
       "        Unique words ratio  Average letters per sentence  \\\n",
       "157453            1.000000                          81.0   \n",
       "426419            0.909091                         101.0   \n",
       "390211            1.000000                          40.5   \n",
       "444164            1.000000                         211.0   \n",
       "40247             1.000000                          58.5   \n",
       "54565             1.000000                          52.0   \n",
       "88023             0.617647                         299.0   \n",
       "570141            1.000000                          97.0   \n",
       "334264            1.000000                         618.0   \n",
       "55870             1.000000                        2733.0   \n",
       "\n",
       "        Variance of letters per sentence  Average words per sentence  \\\n",
       "157453                              0.00                         4.0   \n",
       "426419                              0.00                        11.0   \n",
       "390211                           1560.25                         1.5   \n",
       "444164                          44100.00                         6.5   \n",
       "40247                            1640.25                         2.5   \n",
       "54565                             324.00                         1.0   \n",
       "88023                               0.00                        34.0   \n",
       "570141                              0.00                         1.0   \n",
       "334264                              0.00                        11.0   \n",
       "55870                               0.00                         1.0   \n",
       "\n",
       "        Variance of words per sentence  Maximal uppercase ratio per sentence  \\\n",
       "157453                            0.00                              0.000000   \n",
       "426419                            0.00                              0.049505   \n",
       "390211                            0.25                              0.650000   \n",
       "444164                           30.25                              0.444181   \n",
       "40247                             2.25                              0.151515   \n",
       "54565                             0.00                              0.014286   \n",
       "88023                             0.00                              0.023411   \n",
       "570141                            0.00                              0.000000   \n",
       "334264                            0.00                              0.000000   \n",
       "55870                             0.00                              0.000000   \n",
       "\n",
       "        Length of the maximal uppercase ratio sentence  \\\n",
       "157453                                              81   \n",
       "426419                                             101   \n",
       "390211                                              80   \n",
       "444164                                             421   \n",
       "40247                                               99   \n",
       "54565                                               70   \n",
       "88023                                              299   \n",
       "570141                                              97   \n",
       "334264                                             618   \n",
       "55870                                             2733   \n",
       "\n",
       "                                        text_preprocessed  \n",
       "157453  iiiiiiii lllloooooovvvvvvvveeeeeeeee uuuuuu aa...  \n",
       "426419  arneitai kathgorhmatika lhpsh apagorevmenwn ou...  \n",
       "390211  schooooooooooooooooooooooooooooool 's outttttt...  \n",
       "444164  talklistenproblemsattireattitudebrainstorms tu...  \n",
       "40247   lalalalalalalalalalalalalalalalalalalalala lal...  \n",
       "54565   elo2allveteranbloggers thanx4invitingmerox.wal...  \n",
       "88023   wisteria wisteria wisteria wisteria wisteria w...  \n",
       "570141  ninehoursofschool twodaysaweek foranentireseme...  \n",
       "334264  brandonbiebelbrianandersonmccrankerickostonpau...  \n",
       "55870   lglhfljfljhgkl jlh ljh lkjlkclglhfljfljhgkl jl...  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"text_preprocessed\"].valaues[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
